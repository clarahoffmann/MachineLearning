# Illustrating One-Dimensional Gaussian Processes

This code illustrates the influence of different hyperparameter parametrizations in a Gaussian kernel for a one-dimensional Gaussian process regression. The parametrizations change the data fit and complexity of the mean (and sampled) function(s) of the posterior distribution.
The Gaussian process is conditioned on twenty randomly drawn noisy observations.
The figures are based on Figure 2.5 in "Gaussian Processes in Machine Learning" by Rasmussen & Williams (2006) and Figure 15.3 in "Machine Learning - A Probabilistic Perspective" by Kevin P. Murphy (2012) in R.

# Output

The resulting plot of the Gaussian process conditioned on twenty noisy observations looks like this:

<img src="noisyhyper.jpg" width="400"> 


