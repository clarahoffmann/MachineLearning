# Gaussian Processes
Some Illustration of Gaussian Processes with simulated data. The project is part of a seminar paper in the course "Machine Learning - A Probabilistic Approach" at Humboldt University

See individual folders for code descriptions and useful sources.

Author: Clara Hoffmann

# GP_1D

One-dimensional Gaussian process with noiseless and noisy samples of a sine function and conjugate gradient optimization. partly based on Figure 2.5 in "Gaussian Processes for Machine Learning" by Rasmussen & Williams (2006) and Figure 15.3 in "Machine Learning - A Probabilistic Perspective" by Kevin P. Murphy (2012)

<img src="GP_1D/gpnoerror.jpg" width="250"> <img src="GP_1D/gpnoerror_opt.jpg" width="250"> 

<img src="GP_1D/gperror.jpg" width="250"><img src="GP_1D/gperror_opt.jpg" width="250">

# GP_Hyperparam

One-dimensional Gaussian process with squared exponential kernel and varying hyperparameters,extended representation of figure 5.5 from Rasmussen \& Williams "Gaussian Processes for Machine Learning"

<img src="GP_Hyperparam/noisyhyper.jpg" width="400"> 

# GP_kernels

One-dimensional Gaussian process with different kernels.

<img src="GP_Kernels/gp_kernels.jpg" width="400">

# GP_Likelihood

Development of the log-likelihood of a one-dimensional Gaussian process with varying length scales and hyperparameters (replicates Figure 5.3 from Rasmussen \& Williams "Gaussian Processes for Machine Learning")

<img src="GP_Likelihood/Rasmussen53a.jpg" width="400"> 

<img src="GP_Likelihood/Rasmussen53b.jpg" width="400">
